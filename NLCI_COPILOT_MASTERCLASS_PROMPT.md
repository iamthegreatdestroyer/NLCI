# NLCI Project Initialization: Autonomous Scaffolding Directive
## Master Prompt for GitHub Copilot Agent Mode

---

## ğŸ¯ MISSION DIRECTIVE

You are the **Lead Architect Agent** for the Neural-LSH Code Intelligence (NLCI) project. You have been granted **MAXIMUM AUTONOMY** to design, scaffold, and implement the complete project infrastructure. Execute with the decisiveness and precision of a senior principal engineer who has built developer tools at scale.

**Repository:** `https://github.com/iamthegreatdestroyer/NLCI.git`
**Author:** Stevo (sgbilod / iamthegreatdestroyer)
**License Strategy:** Dual-license (AGPL-3.0 open source + Commercial tiers)

---

## ğŸ“‹ PROJECT SPECIFICATION

### What NLCI Does
Neural-LSH Code Intelligence is a **sub-linear code similarity detection system** that:
1. Indexes codebases in O(n) time using Locality-Sensitive Hashing
2. Queries for similar code blocks in O(1) constant time
3. Detects semantic clones across languages via neural embeddings
4. Streams incremental updates without full re-indexing
5. Integrates as VS Code extension, CLI tool, and embeddable library

### Core Innovation
Traditional clone detection is O(nÂ²). NLCI achieves O(1) query time by:
- Projecting code embeddings through random hyperplanes
- Bucketing similar vectors via hash collisions
- Using multiple hash tables (L tables Ã— K bits) for recall guarantees

---

## ğŸ—ï¸ AUTONOMOUS EXECUTION PROTOCOL

### Phase 1: Repository Structure [EXECUTE IMMEDIATELY]

Create the following monorepo structure using **Turborepo** for build orchestration:

```
NLCI/
â”œâ”€â”€ .github/
â”‚   â”œâ”€â”€ workflows/
â”‚   â”‚   â”œâ”€â”€ ci.yml                    # Continuous integration
â”‚   â”‚   â”œâ”€â”€ release.yml               # Semantic release automation
â”‚   â”‚   â””â”€â”€ security.yml              # Dependency scanning
â”‚   â”œâ”€â”€ ISSUE_TEMPLATE/
â”‚   â”‚   â”œâ”€â”€ bug_report.md
â”‚   â”‚   â”œâ”€â”€ feature_request.md
â”‚   â”‚   â””â”€â”€ config.yml
â”‚   â”œâ”€â”€ PULL_REQUEST_TEMPLATE.md
â”‚   â”œâ”€â”€ CODEOWNERS
â”‚   â””â”€â”€ dependabot.yml
â”‚
â”œâ”€â”€ apps/
â”‚   â”œâ”€â”€ cli/                          # CLI application (Node.js/TypeScript)
â”‚   â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”‚   â”œâ”€â”€ commands/
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ index.ts          # index <path> - Build LSH index
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ scan.ts           # scan <path> - Find clones
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ query.ts          # query <file:line> - Find similar
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ server.ts         # server - Start LSP/API server
â”‚   â”‚   â”‚   â”‚   â””â”€â”€ watch.ts          # watch - Incremental monitoring
â”‚   â”‚   â”‚   â”œâ”€â”€ lib/
â”‚   â”‚   â”‚   â”‚   â””â”€â”€ output-formatters.ts
â”‚   â”‚   â”‚   â””â”€â”€ index.ts              # CLI entry point (Commander.js)
â”‚   â”‚   â”œâ”€â”€ package.json
â”‚   â”‚   â”œâ”€â”€ tsconfig.json
â”‚   â”‚   â””â”€â”€ README.md
â”‚   â”‚
â”‚   â”œâ”€â”€ vscode/                       # VS Code Extension
â”‚   â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”‚   â”œâ”€â”€ extension.ts          # Extension activation
â”‚   â”‚   â”‚   â”œâ”€â”€ providers/
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ clone-lens.ts     # CodeLens for clone indicators
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ hover-provider.ts # Hover info for similar code
â”‚   â”‚   â”‚   â”‚   â””â”€â”€ tree-view.ts      # Clone explorer sidebar
â”‚   â”‚   â”‚   â”œâ”€â”€ commands/
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ find-similar.ts
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ scan-workspace.ts
â”‚   â”‚   â”‚   â”‚   â””â”€â”€ show-clone-report.ts
â”‚   â”‚   â”‚   â””â”€â”€ services/
â”‚   â”‚   â”‚       â””â”€â”€ nlci-client.ts    # Communicates with core engine
â”‚   â”‚   â”œâ”€â”€ package.json              # Extension manifest
â”‚   â”‚   â”œâ”€â”€ tsconfig.json
â”‚   â”‚   â””â”€â”€ README.md
â”‚   â”‚
â”‚   â””â”€â”€ web-demo/                     # Interactive web demonstration
â”‚       â”œâ”€â”€ src/
â”‚       â”‚   â”œâ”€â”€ app/
â”‚       â”‚   â””â”€â”€ components/
â”‚       â”œâ”€â”€ package.json
â”‚       â””â”€â”€ next.config.js
â”‚
â”œâ”€â”€ packages/
â”‚   â”œâ”€â”€ core/                         # Core NLCI Engine (TypeScript)
â”‚   â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”‚   â”œâ”€â”€ index.ts              # Public API exports
â”‚   â”‚   â”‚   â”œâ”€â”€ engine/
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ nlci-engine.ts    # Main orchestration class
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ indexer.ts        # Codebase indexing pipeline
â”‚   â”‚   â”‚   â”‚   â””â”€â”€ query-engine.ts   # Similarity query execution
â”‚   â”‚   â”‚   â”œâ”€â”€ lsh/
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ hash-table.ts     # LSH hash table implementation
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ hyperplane.ts     # Random hyperplane projection
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ bucket-store.ts   # Hash bucket storage
â”‚   â”‚   â”‚   â”‚   â””â”€â”€ lsh-index.ts      # Multi-table LSH index
â”‚   â”‚   â”‚   â”œâ”€â”€ embeddings/
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ embedder.ts       # Abstract embedder interface
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ onnx-embedder.ts  # ONNX Runtime inference
â”‚   â”‚   â”‚   â”‚   â””â”€â”€ models/           # Model weight loading
â”‚   â”‚   â”‚   â”œâ”€â”€ parser/
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ code-parser.ts    # Abstract parser interface
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ tree-sitter/      # Tree-sitter implementations
â”‚   â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ typescript-parser.ts
â”‚   â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ python-parser.ts
â”‚   â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ rust-parser.ts
â”‚   â”‚   â”‚   â”‚   â”‚   â””â”€â”€ parser-registry.ts
â”‚   â”‚   â”‚   â”‚   â””â”€â”€ normalizer.ts     # Code normalization (Î±-rename, etc.)
â”‚   â”‚   â”‚   â”œâ”€â”€ storage/
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ index-store.ts    # Persistent index storage
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ sqlite-store.ts   # SQLite backend
â”‚   â”‚   â”‚   â”‚   â””â”€â”€ memory-store.ts   # In-memory backend
â”‚   â”‚   â”‚   â””â”€â”€ types/
â”‚   â”‚   â”‚       â”œâ”€â”€ code-block.ts     # Code block representation
â”‚   â”‚   â”‚       â”œâ”€â”€ clone-result.ts   # Clone detection results
â”‚   â”‚   â”‚       â””â”€â”€ config.ts         # Configuration types
â”‚   â”‚   â”œâ”€â”€ package.json
â”‚   â”‚   â”œâ”€â”€ tsconfig.json
â”‚   â”‚   â””â”€â”€ README.md
â”‚   â”‚
â”‚   â”œâ”€â”€ lsh-native/                   # High-performance Rust core (optional)
â”‚   â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”‚   â”œâ”€â”€ lib.rs
â”‚   â”‚   â”‚   â”œâ”€â”€ lsh.rs
â”‚   â”‚   â”‚   â””â”€â”€ ffi.rs                # N-API bindings
â”‚   â”‚   â”œâ”€â”€ Cargo.toml
â”‚   â”‚   â””â”€â”€ build.rs
â”‚   â”‚
â”‚   â”œâ”€â”€ shared/                       # Shared types and utilities
â”‚   â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”‚   â”œâ”€â”€ index.ts
â”‚   â”‚   â”‚   â”œâ”€â”€ types.ts
â”‚   â”‚   â”‚   â”œâ”€â”€ constants.ts
â”‚   â”‚   â”‚   â””â”€â”€ utils/
â”‚   â”‚   â”œâ”€â”€ package.json
â”‚   â”‚   â””â”€â”€ tsconfig.json
â”‚   â”‚
â”‚   â””â”€â”€ config/                       # Shared configs
â”‚       â”œâ”€â”€ eslint/
â”‚       â”‚   â””â”€â”€ index.js
â”‚       â”œâ”€â”€ typescript/
â”‚       â”‚   â””â”€â”€ base.json
â”‚       â””â”€â”€ package.json
â”‚
â”œâ”€â”€ models/                           # Pre-trained embedding models
â”‚   â”œâ”€â”€ code-embedder-small/          # Lightweight model (~50MB)
â”‚   â”‚   â”œâ”€â”€ model.onnx
â”‚   â”‚   â”œâ”€â”€ tokenizer.json
â”‚   â”‚   â””â”€â”€ config.json
â”‚   â””â”€â”€ README.md                     # Model documentation
â”‚
â”œâ”€â”€ docs/
â”‚   â”œâ”€â”€ architecture.md               # System architecture
â”‚   â”œâ”€â”€ algorithms.md                 # LSH algorithm explanation
â”‚   â”œâ”€â”€ api-reference.md              # API documentation
â”‚   â”œâ”€â”€ cli-reference.md              # CLI commands
â”‚   â”œâ”€â”€ vscode-extension.md           # Extension usage
â”‚   â””â”€â”€ commercial-licensing.md       # Commercial license info
â”‚
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ setup.sh                      # Initial setup script
â”‚   â”œâ”€â”€ download-models.ts            # Model downloader
â”‚   â””â”€â”€ benchmark.ts                  # Performance benchmarking
â”‚
â”œâ”€â”€ examples/
â”‚   â”œâ”€â”€ basic-usage/
â”‚   â”œâ”€â”€ ci-integration/
â”‚   â””â”€â”€ custom-embedder/
â”‚
â”œâ”€â”€ benchmarks/
â”‚   â”œâ”€â”€ datasets/                     # Benchmark datasets (gitignored)
â”‚   â”œâ”€â”€ results/
â”‚   â””â”€â”€ run-benchmarks.ts
â”‚
â”œâ”€â”€ turbo.json                        # Turborepo configuration
â”œâ”€â”€ package.json                      # Root package.json (workspaces)
â”œâ”€â”€ pnpm-workspace.yaml               # PNPM workspace config
â”œâ”€â”€ tsconfig.json                     # Root TypeScript config
â”œâ”€â”€ .eslintrc.js                      # ESLint configuration
â”œâ”€â”€ .prettierrc                       # Prettier configuration
â”œâ”€â”€ .gitignore
â”œâ”€â”€ .nvmrc                            # Node version
â”œâ”€â”€ LICENSE                           # AGPL-3.0 license
â”œâ”€â”€ LICENSE-COMMERCIAL.md             # Commercial license terms
â”œâ”€â”€ CONTRIBUTING.md
â”œâ”€â”€ SECURITY.md
â”œâ”€â”€ CHANGELOG.md
â””â”€â”€ README.md                         # Project overview
```

### Phase 2: Configuration Files [EXECUTE IMMEDIATELY AFTER STRUCTURE]

Generate production-grade configurations:

#### `package.json` (root)
```json
{
  "name": "nlci-monorepo",
  "version": "0.0.0",
  "private": true,
  "description": "Neural-LSH Code Intelligence - Sub-linear semantic clone detection",
  "author": "Stevo <sgbilod@proton.me>",
  "license": "AGPL-3.0-or-later",
  "repository": {
    "type": "git",
    "url": "https://github.com/iamthegreatdestroyer/NLCI.git"
  },
  "homepage": "https://github.com/iamthegreatdestroyer/NLCI",
  "bugs": {
    "url": "https://github.com/iamthegreatdestroyer/NLCI/issues"
  },
  "keywords": [
    "code-clone-detection",
    "lsh",
    "locality-sensitive-hashing",
    "semantic-code-analysis",
    "code-similarity",
    "developer-tools",
    "static-analysis"
  ],
  "engines": {
    "node": ">=20.0.0",
    "pnpm": ">=8.0.0"
  },
  "packageManager": "pnpm@8.15.0",
  "scripts": {
    "build": "turbo build",
    "dev": "turbo dev",
    "lint": "turbo lint",
    "lint:fix": "turbo lint:fix",
    "test": "turbo test",
    "test:coverage": "turbo test:coverage",
    "typecheck": "turbo typecheck",
    "clean": "turbo clean && rm -rf node_modules",
    "format": "prettier --write \"**/*.{ts,tsx,js,jsx,json,md}\"",
    "format:check": "prettier --check \"**/*.{ts,tsx,js,jsx,json,md}\"",
    "prepare": "husky install",
    "release": "changeset publish",
    "version": "changeset version"
  },
  "devDependencies": {
    "@changesets/cli": "^2.27.0",
    "@types/node": "^20.10.0",
    "eslint": "^8.56.0",
    "husky": "^8.0.3",
    "lint-staged": "^15.2.0",
    "prettier": "^3.2.0",
    "turbo": "^1.12.0",
    "typescript": "^5.3.0",
    "vitest": "^1.2.0"
  },
  "lint-staged": {
    "*.{ts,tsx,js,jsx}": [
      "eslint --fix",
      "prettier --write"
    ],
    "*.{json,md}": [
      "prettier --write"
    ]
  }
}
```

#### `turbo.json`
```json
{
  "$schema": "https://turbo.build/schema.json",
  "globalDependencies": ["**/.env.*local"],
  "pipeline": {
    "build": {
      "dependsOn": ["^build"],
      "outputs": ["dist/**", ".next/**", "*.vsix"]
    },
    "dev": {
      "cache": false,
      "persistent": true
    },
    "lint": {
      "dependsOn": ["^build"]
    },
    "lint:fix": {
      "dependsOn": ["^build"]
    },
    "test": {
      "dependsOn": ["build"],
      "outputs": ["coverage/**"]
    },
    "test:coverage": {
      "dependsOn": ["build"],
      "outputs": ["coverage/**"]
    },
    "typecheck": {
      "dependsOn": ["^build"]
    },
    "clean": {
      "cache": false
    }
  }
}
```

#### `pnpm-workspace.yaml`
```yaml
packages:
  - 'apps/*'
  - 'packages/*'
```

#### `.github/workflows/ci.yml`
```yaml
name: CI

on:
  push:
    branches: [main, develop]
  pull_request:
    branches: [main, develop]

concurrency:
  group: ${{ github.workflow }}-${{ github.ref }}
  cancel-in-progress: true

jobs:
  build-and-test:
    runs-on: ubuntu-latest
    strategy:
      matrix:
        node-version: [20.x, 22.x]
    
    steps:
      - name: Checkout
        uses: actions/checkout@v4
        with:
          fetch-depth: 2

      - name: Setup pnpm
        uses: pnpm/action-setup@v2
        with:
          version: 8

      - name: Setup Node.js ${{ matrix.node-version }}
        uses: actions/setup-node@v4
        with:
          node-version: ${{ matrix.node-version }}
          cache: 'pnpm'

      - name: Install dependencies
        run: pnpm install --frozen-lockfile

      - name: Build
        run: pnpm build

      - name: Lint
        run: pnpm lint

      - name: Type Check
        run: pnpm typecheck

      - name: Test
        run: pnpm test:coverage

      - name: Upload coverage
        uses: codecov/codecov-action@v3
        with:
          files: ./packages/core/coverage/lcov.info
          fail_ci_if_error: false

  publish-preview:
    needs: build-and-test
    if: github.event_name == 'pull_request'
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      - uses: pnpm/action-setup@v2
        with:
          version: 8
      - uses: actions/setup-node@v4
        with:
          node-version: 20
          cache: 'pnpm'
      - run: pnpm install --frozen-lockfile
      - run: pnpm build
      # Preview deployment logic here
```

### Phase 3: Core Package Implementation [EXECUTE SYSTEMATICALLY]

#### `packages/core/src/index.ts` - Public API
```typescript
/**
 * NLCI - Neural-LSH Code Intelligence
 * Sub-linear semantic code clone detection
 * 
 * @packageDocumentation
 * @module @nlci/core
 * @license AGPL-3.0-or-later
 * 
 * Commercial licensing available at https://github.com/iamthegreatdestroyer/NLCI
 */

export { NLCIEngine, type NLCIEngineConfig } from './engine/nlci-engine';
export { LSHIndex, type LSHIndexConfig } from './lsh/lsh-index';
export { CodeParser, type ParseResult } from './parser/code-parser';
export { Embedder, type EmbeddingResult } from './embeddings/embedder';

// Types
export type { CodeBlock, CodeBlockMetadata } from './types/code-block';
export type { CloneResult, CloneCluster, ClonePair } from './types/clone-result';
export type { NLCIConfig, StorageBackend, EmbedderBackend } from './types/config';

// Utilities
export { createNLCI } from './factory';
export { version } from './version';
```

#### `packages/core/src/lsh/lsh-index.ts` - Core LSH Implementation
```typescript
/**
 * Multi-table Locality-Sensitive Hashing Index
 * 
 * Achieves O(1) query time for approximate nearest neighbor search
 * by projecting high-dimensional embeddings through random hyperplanes.
 */

import { Hyperplane, HyperplaneProjection } from './hyperplane';
import { HashTable, BucketEntry } from './hash-table';
import { BucketStore } from './bucket-store';
import type { CodeBlock } from '../types/code-block';

export interface LSHIndexConfig {
  /** Number of hash tables (L). More tables = better recall, more memory */
  numTables: number;
  /** Number of hash bits per table (K). More bits = higher precision, lower recall */
  numBits: number;
  /** Dimensionality of input embeddings */
  embeddingDim: number;
  /** Random seed for reproducibility */
  seed?: number;
  /** Storage backend for persistence */
  storage?: BucketStore;
}

export interface QueryResult {
  block: CodeBlock;
  similarity: number;
  hashCollisions: number;
}

export class LSHIndex {
  private readonly config: Required<LSHIndexConfig>;
  private readonly tables: HashTable[];
  private readonly projections: HyperplaneProjection[];
  private indexedCount: number = 0;

  constructor(config: LSHIndexConfig) {
    this.config = {
      numTables: config.numTables,
      numBits: config.numBits,
      embeddingDim: config.embeddingDim,
      seed: config.seed ?? Date.now(),
      storage: config.storage ?? new Map(),
    };

    // Initialize L hash tables with K random hyperplanes each
    this.tables = [];
    this.projections = [];
    
    for (let t = 0; t < this.config.numTables; t++) {
      const projection = new HyperplaneProjection(
        this.config.embeddingDim,
        this.config.numBits,
        this.config.seed + t
      );
      this.projections.push(projection);
      this.tables.push(new HashTable(t));
    }
  }

  /**
   * Index a code block embedding
   * Time complexity: O(L * K) = O(1) for fixed L, K
   */
  insert(block: CodeBlock, embedding: Float32Array): void {
    if (embedding.length !== this.config.embeddingDim) {
      throw new Error(
        `Embedding dimension mismatch: expected ${this.config.embeddingDim}, got ${embedding.length}`
      );
    }

    for (let t = 0; t < this.config.numTables; t++) {
      const hash = this.projections[t].project(embedding);
      this.tables[t].insert(hash, block);
    }
    
    this.indexedCount++;
  }

  /**
   * Query for similar code blocks
   * Time complexity: O(L * K + C) where C is collision count (typically small)
   */
  query(embedding: Float32Array, maxResults: number = 10): QueryResult[] {
    const candidates = new Map<string, { block: CodeBlock; collisions: number }>();

    // Collect candidates from all tables
    for (let t = 0; t < this.config.numTables; t++) {
      const hash = this.projections[t].project(embedding);
      const bucket = this.tables[t].get(hash);
      
      for (const block of bucket) {
        const key = block.id;
        const existing = candidates.get(key);
        if (existing) {
          existing.collisions++;
        } else {
          candidates.set(key, { block, collisions: 1 });
        }
      }
    }

    // Rank by collision count (proxy for similarity)
    const results = Array.from(candidates.values())
      .sort((a, b) => b.collisions - a.collisions)
      .slice(0, maxResults)
      .map(({ block, collisions }) => ({
        block,
        similarity: collisions / this.config.numTables,
        hashCollisions: collisions,
      }));

    return results;
  }

  /**
   * Get index statistics
   */
  getStats(): LSHIndexStats {
    return {
      indexedCount: this.indexedCount,
      numTables: this.config.numTables,
      numBits: this.config.numBits,
      embeddingDim: this.config.embeddingDim,
      memoryUsage: this.estimateMemoryUsage(),
    };
  }

  private estimateMemoryUsage(): number {
    // Rough estimate in bytes
    let total = 0;
    for (const table of this.tables) {
      total += table.estimateMemoryUsage();
    }
    return total;
  }

  /**
   * Serialize index to buffer for persistence
   */
  async serialize(): Promise<Buffer> {
    // Implementation for persistence
    throw new Error('Not implemented');
  }

  /**
   * Load index from serialized buffer
   */
  static async deserialize(buffer: Buffer): Promise<LSHIndex> {
    // Implementation for loading
    throw new Error('Not implemented');
  }
}

export interface LSHIndexStats {
  indexedCount: number;
  numTables: number;
  numBits: number;
  embeddingDim: number;
  memoryUsage: number;
}
```

#### `packages/core/src/lsh/hyperplane.ts` - Random Hyperplane Projection
```typescript
/**
 * Random Hyperplane Projection for LSH
 * 
 * Projects high-dimensional vectors to binary hash codes using
 * random hyperplanes. Preserves angular similarity with high probability.
 */

import { createHash } from 'crypto';

export class HyperplaneProjection {
  private readonly hyperplanes: Float32Array[];
  private readonly dim: number;
  private readonly numBits: number;

  constructor(dim: number, numBits: number, seed: number) {
    this.dim = dim;
    this.numBits = numBits;
    this.hyperplanes = [];

    // Generate K random hyperplanes using seeded PRNG
    const rng = createSeededRNG(seed);
    
    for (let k = 0; k < numBits; k++) {
      const hyperplane = new Float32Array(dim);
      for (let d = 0; d < dim; d++) {
        // Box-Muller transform for normal distribution
        hyperplane[d] = rng.nextGaussian();
      }
      // Normalize to unit vector
      normalize(hyperplane);
      this.hyperplanes.push(hyperplane);
    }
  }

  /**
   * Project embedding to K-bit hash code
   * Time complexity: O(K * D) where D is embedding dimension
   */
  project(embedding: Float32Array): bigint {
    let hash = 0n;
    
    for (let k = 0; k < this.numBits; k++) {
      // Compute dot product with hyperplane
      const dot = dotProduct(embedding, this.hyperplanes[k]);
      
      // Set bit if dot product is positive
      if (dot >= 0) {
        hash |= 1n << BigInt(k);
      }
    }
    
    return hash;
  }
}

// Seeded PRNG with Gaussian output
function createSeededRNG(seed: number) {
  let state = seed;
  
  const next = () => {
    state = (state * 1103515245 + 12345) & 0x7fffffff;
    return state / 0x7fffffff;
  };
  
  let spare: number | null = null;
  
  return {
    next,
    nextGaussian(): number {
      if (spare !== null) {
        const val = spare;
        spare = null;
        return val;
      }
      
      // Box-Muller transform
      let u, v, s;
      do {
        u = next() * 2 - 1;
        v = next() * 2 - 1;
        s = u * u + v * v;
      } while (s >= 1 || s === 0);
      
      const mul = Math.sqrt(-2 * Math.log(s) / s);
      spare = v * mul;
      return u * mul;
    },
  };
}

function dotProduct(a: Float32Array, b: Float32Array): number {
  let sum = 0;
  for (let i = 0; i < a.length; i++) {
    sum += a[i] * b[i];
  }
  return sum;
}

function normalize(vec: Float32Array): void {
  let norm = 0;
  for (let i = 0; i < vec.length; i++) {
    norm += vec[i] * vec[i];
  }
  norm = Math.sqrt(norm);
  if (norm > 0) {
    for (let i = 0; i < vec.length; i++) {
      vec[i] /= norm;
    }
  }
}
```

### Phase 4: CLI Application [EXECUTE AFTER CORE]

#### `apps/cli/src/index.ts`
```typescript
#!/usr/bin/env node
/**
 * NLCI CLI - Neural-LSH Code Intelligence Command Line Interface
 * 
 * @license AGPL-3.0-or-later
 */

import { Command } from 'commander';
import { version } from '@nlci/core';
import { indexCommand } from './commands/index';
import { scanCommand } from './commands/scan';
import { queryCommand } from './commands/query';
import { serverCommand } from './commands/server';
import { watchCommand } from './commands/watch';

const program = new Command();

program
  .name('nlci')
  .description('Neural-LSH Code Intelligence - Sub-linear semantic clone detection')
  .version(version)
  .option('-v, --verbose', 'Enable verbose output')
  .option('-c, --config <path>', 'Path to configuration file');

program.addCommand(indexCommand);
program.addCommand(scanCommand);
program.addCommand(queryCommand);
program.addCommand(serverCommand);
program.addCommand(watchCommand);

program.parse();
```

#### `apps/cli/src/commands/scan.ts`
```typescript
/**
 * Scan command - Detect code clones in a codebase
 */

import { Command } from 'commander';
import { NLCIEngine, type CloneCluster } from '@nlci/core';
import ora from 'ora';
import chalk from 'chalk';

export const scanCommand = new Command('scan')
  .description('Scan a codebase for code clones')
  .argument('<path>', 'Path to scan')
  .option('-t, --threshold <number>', 'Similarity threshold (0-1)', '0.85')
  .option('-o, --output <format>', 'Output format (json|table|summary)', 'table')
  .option('-i, --index <path>', 'Use existing index file')
  .option('--include <patterns...>', 'File patterns to include')
  .option('--exclude <patterns...>', 'File patterns to exclude')
  .option('--min-lines <number>', 'Minimum lines for a code block', '5')
  .option('--cross-language', 'Enable cross-language detection')
  .action(async (path: string, options) => {
    const spinner = ora('Initializing NLCI engine...').start();
    
    try {
      const engine = await NLCIEngine.create({
        threshold: parseFloat(options.threshold),
        minLines: parseInt(options.minLines),
        crossLanguage: options.crossLanguage,
      });

      spinner.text = 'Indexing codebase...';
      const indexStats = await engine.indexDirectory(path, {
        include: options.include,
        exclude: options.exclude,
      });
      
      spinner.text = `Indexed ${indexStats.fileCount} files, ${indexStats.blockCount} code blocks`;

      spinner.text = 'Detecting clones...';
      const clusters = await engine.findClones();
      
      spinner.succeed(`Found ${clusters.length} clone clusters`);

      // Output results
      formatOutput(clusters, options.output);

    } catch (error) {
      spinner.fail('Scan failed');
      console.error(chalk.red(error instanceof Error ? error.message : error));
      process.exit(1);
    }
  });

function formatOutput(clusters: CloneCluster[], format: string): void {
  switch (format) {
    case 'json':
      console.log(JSON.stringify(clusters, null, 2));
      break;
    case 'summary':
      console.log(chalk.bold(`\nClone Detection Summary\n`));
      console.log(`Total clusters: ${clusters.length}`);
      console.log(`Total clone pairs: ${clusters.reduce((acc, c) => acc + c.pairs.length, 0)}`);
      break;
    case 'table':
    default:
      printCloneTable(clusters);
  }
}

function printCloneTable(clusters: CloneCluster[]): void {
  console.log(chalk.bold('\nClone Clusters:\n'));
  
  for (const [i, cluster] of clusters.entries()) {
    const severity = cluster.similarity > 0.95 
      ? chalk.red('â—') 
      : cluster.similarity > 0.85 
        ? chalk.yellow('â—') 
        : chalk.green('â—');
    
    console.log(`${severity} Cluster #${i + 1} (${(cluster.similarity * 100).toFixed(1)}% similar)`);
    
    for (const block of cluster.blocks) {
      console.log(chalk.gray(`   ${block.file}:${block.startLine}-${block.endLine}`));
    }
    console.log();
  }
}
```

### Phase 5: VS Code Extension [EXECUTE AFTER CLI]

#### `apps/vscode/package.json`
```json
{
  "name": "nlci-vscode",
  "displayName": "NLCI - Neural Code Intelligence",
  "description": "Sub-linear semantic code clone detection powered by LSH",
  "version": "0.0.1",
  "publisher": "iamthegreatdestroyer",
  "repository": {
    "type": "git",
    "url": "https://github.com/iamthegreatdestroyer/NLCI.git"
  },
  "engines": {
    "vscode": "^1.85.0"
  },
  "categories": [
    "Linters",
    "Programming Languages",
    "Other"
  ],
  "activationEvents": [
    "onStartupFinished"
  ],
  "main": "./dist/extension.js",
  "contributes": {
    "commands": [
      {
        "command": "nlci.scanWorkspace",
        "title": "NLCI: Scan Workspace for Clones"
      },
      {
        "command": "nlci.findSimilar",
        "title": "NLCI: Find Similar Code"
      },
      {
        "command": "nlci.showCloneReport",
        "title": "NLCI: Show Clone Report"
      }
    ],
    "views": {
      "explorer": [
        {
          "id": "nlciCloneExplorer",
          "name": "Clone Explorer"
        }
      ]
    },
    "configuration": {
      "title": "NLCI",
      "properties": {
        "nlci.threshold": {
          "type": "number",
          "default": 0.85,
          "description": "Similarity threshold for clone detection"
        },
        "nlci.autoScan": {
          "type": "boolean",
          "default": true,
          "description": "Automatically scan workspace on open"
        },
        "nlci.showCodeLens": {
          "type": "boolean",
          "default": true,
          "description": "Show clone indicators as CodeLens"
        }
      }
    }
  },
  "scripts": {
    "vscode:prepublish": "pnpm run build",
    "build": "esbuild ./src/extension.ts --bundle --outfile=dist/extension.js --external:vscode --format=cjs --platform=node",
    "watch": "pnpm run build --watch",
    "package": "vsce package --no-dependencies",
    "publish": "vsce publish --no-dependencies"
  },
  "devDependencies": {
    "@types/vscode": "^1.85.0",
    "@vscode/vsce": "^2.22.0",
    "esbuild": "^0.19.0"
  },
  "dependencies": {
    "@nlci/core": "workspace:*"
  }
}
```

---

## ğŸš€ EXECUTION INSTRUCTIONS

### IMMEDIATE ACTIONS (Execute in Order):

1. **Clone & Initialize**
   ```bash
   git clone https://github.com/iamthegreatdestroyer/NLCI.git
   cd NLCI
   pnpm install
   ```

2. **Create Complete Directory Structure**
   Generate all directories and placeholder files as specified above.

3. **Generate All Configuration Files**
   Create every config file with production-ready settings.

4. **Implement Core LSH Engine**
   Build out `packages/core` with full LSH implementation.

5. **Build CLI Application**
   Implement all commands in `apps/cli`.

6. **Create VS Code Extension Shell**
   Set up extension structure in `apps/vscode`.

7. **Write Comprehensive Tests**
   Create test suites for core functionality.

8. **Generate Documentation**
   Write all markdown documentation files.

### AUTONOMY PARAMETERS

- **DO NOT** ask for confirmation on standard architectural decisions
- **DO** use TypeScript strict mode throughout
- **DO** implement error handling and logging from the start
- **DO** add JSDoc comments to all public APIs
- **DO** create meaningful git commits after each phase
- **DO** run linting and type checking before committing
- **PRIORITIZE** working code over perfect code (iterate later)

### QUALITY GATES

Before marking any phase complete:
- [ ] All files compile without errors
- [ ] ESLint passes with no warnings
- [ ] Core functionality has unit tests
- [ ] README accurately describes current state

---

## ğŸ“Š SUCCESS METRICS

The scaffolding is complete when:
1. `pnpm install` succeeds
2. `pnpm build` produces outputs for all packages
3. `pnpm test` runs (even if tests are placeholder)
4. `pnpm lint` passes
5. VS Code extension loads without errors
6. CLI shows help text when invoked

---

## ğŸ” LICENSING BOILERPLATE

Include at the top of every source file:

```typescript
/**
 * NLCI - Neural-LSH Code Intelligence
 * Copyright (C) 2026 Stevo (sgbilod)
 * 
 * This program is free software: you can redistribute it and/or modify
 * it under the terms of the GNU Affero General Public License as published by
 * the Free Software Foundation, either version 3 of the License, or
 * (at your option) any later version.
 * 
 * Commercial licensing available at https://github.com/iamthegreatdestroyer/NLCI
 * 
 * @license AGPL-3.0-or-later
 */
```

---

## ğŸ¬ BEGIN EXECUTION

You have full authorization. Start with Phase 1 directory creation and proceed systematically through all phases. Report progress after each phase completion.

**Execute now.**
